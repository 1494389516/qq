#!/usr/bin/env python3

"""
å¢å¼ºé£æ§æ¨¡å‹ç³»ç»Ÿ - é›†æˆXGBoostã€LightGBMã€éšæœºæ£®æ—çš„å¤šæ¨¡å‹æ¡†æ¶
è®¾è®¡ç›®æ ‡ï¼šæ„å»ºé£æ§ç®—æ³•ä¸“å®¶çº§çš„ç†è®ºæ¡†æ¶å’Œæ•°å­¦å»ºæ¨¡èƒ½åŠ›

æ ¸å¿ƒç®—æ³•æ¨¡å—ï¼š
1. æ¢¯åº¦æå‡æ¨¡å‹é›†æˆ (XGBoost + LightGBM + RandomForest)
2. è´å¶æ–¯è¶…å‚æ•°ä¼˜åŒ–
3. A/Bæµ‹è¯•ç†è®ºæ¡†æ¶
4. æ¨¡å‹è§£é‡Šæ€§åˆ†æ (SHAP + LIME)
"""

import time
import numpy as np
import pandas as pd
import warnings
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum
from abc import ABC, abstractmethod

# æ ¸å¿ƒæœºå™¨å­¦ä¹ åº“
import xgboost as xgb
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score

# è¶…å‚æ•°ä¼˜åŒ–
import optuna
from optuna.samplers import TPESampler

# A/Bæµ‹è¯•
from scipy import stats

# å¯¼å…¥åŸºç¡€æ¨¡å—
try:
    from éšæœºæ£®æ—ç®—æ³•_æ¶æ„è¡Œä¸ºè¯†åˆ« import AttackType, AttackFeatures, AttackDataGenerator
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å®šä¹‰
    class AttackType(Enum):
        NORMAL = 0
        CRAWLER = 1
        BRUTE_FORCE = 2
        ORDER_FRAUD = 3
        PAYMENT_FRAUD = 4
        DDOS = 5
    
    # å¤ç”¨AttackDataGenerator
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from éšæœºæ£®æ—ç®—æ³•_æ¶æ„è¡Œä¸ºè¯†åˆ« import AttackDataGenerator

warnings.filterwarnings('ignore')


@dataclass 
class ModelPerformanceMetrics:
    """æ¨¡å‹æ€§èƒ½æŒ‡æ ‡"""
    accuracy: float
    f1_score: float
    auc_score: float
    training_time: float
    

@dataclass
class ABTestResult:
    """A/Bæµ‹è¯•ç»“æœ"""
    model_a_name: str
    model_b_name: str
    p_value: float
    effect_size: float
    is_significant: bool
    winner: str


class ModelType(Enum):
    """æ¨¡å‹ç±»å‹æšä¸¾"""
    RANDOM_FOREST = "random_forest"
    XGBOOST = "xgboost" 
    LIGHTGBM = "lightgbm"
    ENSEMBLE = "ensemble"


class BaseRiskModel(ABC):
    """é£æ§æ¨¡å‹åŸºç±» - æŠ½è±¡ç†è®ºæ¡†æ¶"""
    
    def __init__(self, model_name: str):
        self.model_name = model_name
        self.model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.logger = logging.getLogger(f"{__name__}.{model_name}")
        
    @abstractmethod
    def build_model(self, hyperparams: Dict[str, Any]) -> Any:
        """æ„å»ºæ¨¡å‹æ¶æ„"""
        pass
        
    @abstractmethod
    def train_model(self, X: np.ndarray, y: np.ndarray, **kwargs) -> ModelPerformanceMetrics:
        """è®­ç»ƒæ¨¡å‹"""
        pass
        
    def predict(self, X: np.ndarray) -> np.ndarray:
        """æ¨¡å‹é¢„æµ‹"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)
        
    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """æ¦‚ç‡é¢„æµ‹"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        X_scaled = self.scaler.transform(X)
        return self.model.predict_proba(X_scaled)


class XGBoostRiskModel(BaseRiskModel):
    """XGBoosté£æ§æ¨¡å‹ - æ¢¯åº¦æå‡å†³ç­–æ ‘"""
    
    def __init__(self):
        super().__init__("XGBoost")
        
    def build_model(self, hyperparams: Dict[str, Any]) -> xgb.XGBClassifier:
        """æ„å»ºXGBoostæ¨¡å‹"""
        return xgb.XGBClassifier(
            n_estimators=hyperparams.get('n_estimators', 200),
            max_depth=hyperparams.get('max_depth', 8),
            learning_rate=hyperparams.get('learning_rate', 0.1),
            subsample=hyperparams.get('subsample', 0.8),
            colsample_bytree=hyperparams.get('colsample_bytree', 0.8),
            reg_alpha=hyperparams.get('reg_alpha', 0.1),
            reg_lambda=hyperparams.get('reg_lambda', 1.0),
            objective='multi:softprob',
            random_state=42,
            n_jobs=-1,
            verbosity=0
        )
        
    def train_model(self, X: np.ndarray, y: np.ndarray, **kwargs) -> ModelPerformanceMetrics:
        """è®­ç»ƒXGBoostæ¨¡å‹"""
        start_time = time.time()
        
        # æ•°æ®é¢„å¤„ç†
        X_scaled = self.scaler.fit_transform(X)
        
        # æ„å»ºæ¨¡å‹
        hyperparams = kwargs.get('hyperparams', {})
        self.model = self.build_model(hyperparams)
        
        # è®­ç»ƒé›†éªŒè¯é›†åˆ†å‰²
        X_train, X_val, y_train, y_val = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # è®­ç»ƒæ¨¡å‹
        self.model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            early_stopping_rounds=20,
            verbose=False
        )
        
        training_time = time.time() - start_time
        self.is_trained = True
        
        # è¯„ä¼°æ€§èƒ½
        y_pred = self.model.predict(X_val)
        y_proba = self.model.predict_proba(X_val)
        
        metrics = ModelPerformanceMetrics(
            accuracy=float(accuracy_score(y_val, y_pred)),
            f1_score=float(f1_score(y_val, y_pred, average='weighted')),
            auc_score=float(roc_auc_score(y_val, y_proba, multi_class='ovr')),
            training_time=training_time
        )
        
        self.logger.info(f"XGBoostè®­ç»ƒå®Œæˆ - å‡†ç¡®ç‡: {metrics.accuracy:.4f}")
        return metrics


class LightGBMRiskModel(BaseRiskModel):
    """LightGBMé£æ§æ¨¡å‹ - åŸºäºç›´æ–¹å›¾çš„æ¢¯åº¦æå‡"""
    
    def __init__(self):
        super().__init__("LightGBM")
        
    def build_model(self, hyperparams: Dict[str, Any]) -> lgb.LGBMClassifier:
        """æ„å»ºLightGBMæ¨¡å‹"""
        return lgb.LGBMClassifier(
            n_estimators=hyperparams.get('n_estimators', 200),
            max_depth=hyperparams.get('max_depth', 8),
            learning_rate=hyperparams.get('learning_rate', 0.1),
            num_leaves=hyperparams.get('num_leaves', 31),
            subsample=hyperparams.get('subsample', 0.8),
            colsample_bytree=hyperparams.get('colsample_bytree', 0.8),
            reg_alpha=hyperparams.get('reg_alpha', 0.1),
            reg_lambda=hyperparams.get('reg_lambda', 1.0),
            objective='multiclass',
            random_state=42,
            n_jobs=-1,
            verbosity=-1
        )
        
    def train_model(self, X: np.ndarray, y: np.ndarray, **kwargs) -> ModelPerformanceMetrics:
        """è®­ç»ƒLightGBMæ¨¡å‹"""
        start_time = time.time()
        
        X_scaled = self.scaler.fit_transform(X)
        hyperparams = kwargs.get('hyperparams', {})
        self.model = self.build_model(hyperparams)
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
        
        self.model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            early_stopping_rounds=20,
            verbose=False
        )
        
        training_time = time.time() - start_time
        self.is_trained = True
        
        y_pred = self.model.predict(X_val)
        y_proba = self.model.predict_proba(X_val)
        
        metrics = ModelPerformanceMetrics(
            accuracy=float(accuracy_score(y_val, y_pred)),
            f1_score=float(f1_score(y_val, y_pred, average='weighted')),
            auc_score=float(roc_auc_score(y_val, y_proba, multi_class='ovr')),
            training_time=training_time
        )
        
        self.logger.info(f"LightGBMè®­ç»ƒå®Œæˆ - å‡†ç¡®ç‡: {metrics.accuracy:.4f}")
        return metrics


class RandomForestRiskModel(BaseRiskModel):
    """éšæœºæ£®æ—é£æ§æ¨¡å‹ - æ”¹è¿›ç‰ˆ"""
    
    def __init__(self):
        super().__init__("RandomForest")
        
    def build_model(self, hyperparams: Dict[str, Any]) -> RandomForestClassifier:
        """æ„å»ºéšæœºæ£®æ—æ¨¡å‹"""
        return RandomForestClassifier(
            n_estimators=hyperparams.get('n_estimators', 200),
            max_depth=hyperparams.get('max_depth', 15),
            min_samples_split=hyperparams.get('min_samples_split', 5),
            min_samples_leaf=hyperparams.get('min_samples_leaf', 2),
            max_features=hyperparams.get('max_features', 'sqrt'),
            random_state=42,
            n_jobs=-1,
            class_weight='balanced'
        )
        
    def train_model(self, X: np.ndarray, y: np.ndarray, **kwargs) -> ModelPerformanceMetrics:
        """è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹"""
        start_time = time.time()
        
        X_scaled = self.scaler.fit_transform(X)
        hyperparams = kwargs.get('hyperparams', {})
        self.model = self.build_model(hyperparams)
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
        
        self.model.fit(X_train, y_train)
        
        training_time = time.time() - start_time
        self.is_trained = True
        
        y_pred = self.model.predict(X_val)
        y_proba = self.model.predict_proba(X_val)
        
        metrics = ModelPerformanceMetrics(
            accuracy=float(accuracy_score(y_val, y_pred)),
            f1_score=float(f1_score(y_val, y_pred, average='weighted')),
            auc_score=float(roc_auc_score(y_val, y_proba, multi_class='ovr')),
            training_time=training_time
        )
        
        self.logger.info(f"éšæœºæ£®æ—è®­ç»ƒå®Œæˆ - å‡†ç¡®ç‡: {metrics.accuracy:.4f}")
        return metrics


class BayesianHyperparameterOptimizer:
    """è´å¶æ–¯è¶…å‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self, n_trials: int = 50):
        self.n_trials = n_trials
        self.logger = logging.getLogger(f"{__name__}.BayesianOptimizer")
        
    def optimize_xgboost(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        """ä¼˜åŒ–XGBoostè¶…å‚æ•°"""
        
        def objective(trial):
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 100, 300),
                'max_depth': trial.suggest_int('max_depth', 3, 10),
                'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),
                'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),
                'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),
                'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0)
            }
            
            model = XGBoostRiskModel()
            scores = []
            
            skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
            for train_idx, val_idx in skf.split(X, y):
                X_train, X_val = X[train_idx], X[val_idx]
                y_train, y_val = y[train_idx], y[val_idx]
                
                model.train_model(X_train, y_train, hyperparams=params)
                metrics = model.evaluate_model(X_val, y_val)
                scores.append(metrics.f1_score)
                
            return np.mean(scores)
        
        study = optuna.create_study(direction='maximize', sampler=TPESampler())
        study.optimize(objective, n_trials=self.n_trials)
        
        self.logger.info(f"XGBoostæœ€ä¼˜å‚æ•°: {study.best_params}")
        return study.best_params


class EnsembleRiskModel:
    """é›†æˆé£æ§æ¨¡å‹ - å¤šæ¨¡å‹èåˆ"""
    
    def __init__(self):
        self.models = {
            'xgboost': XGBoostRiskModel(),
            'lightgbm': LightGBMRiskModel(), 
            'random_forest': RandomForestRiskModel()
        }
        self.weights = {}
        self.is_trained = False
        self.logger = logging.getLogger(f"{__name__}.EnsembleModel")
        
    def train_ensemble(self, X: np.ndarray, y: np.ndarray, 
                      hyperparams: Dict[str, Dict] = None) -> Dict[str, ModelPerformanceMetrics]:
        """è®­ç»ƒé›†æˆæ¨¡å‹"""
        if hyperparams is None:
            hyperparams = {}
            
        performance_metrics = {}
        
        # è®­ç»ƒå„ä¸ªå­æ¨¡å‹
        for model_name, model in self.models.items():
            model_hyperparams = hyperparams.get(model_name, {})
            metrics = model.train_model(X, y, hyperparams=model_hyperparams)
            performance_metrics[model_name] = metrics
            
        # è®¡ç®—é›†æˆæƒé‡ï¼ˆåŸºäºF1åˆ†æ•°ï¼‰
        f1_scores = {name: metrics.f1_score for name, metrics in performance_metrics.items()}
        total_f1 = sum(f1_scores.values())
        self.weights = {name: score / total_f1 for name, score in f1_scores.items()}
        
        self.is_trained = True
        self.logger.info(f"é›†æˆæ¨¡å‹æƒé‡: {self.weights}")
        
        return performance_metrics
        
    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """é›†æˆæ¦‚ç‡é¢„æµ‹"""
        if not self.is_trained:
            raise ValueError("é›†æˆæ¨¡å‹æœªè®­ç»ƒ")
            
        # è·å–å„æ¨¡å‹é¢„æµ‹æ¦‚ç‡
        predictions = {}
        for model_name, model in self.models.items():
            predictions[model_name] = model.predict_proba(X)
            
        # åŠ æƒé›†æˆ
        ensemble_proba = np.zeros_like(predictions['xgboost'])
        for model_name, proba in predictions.items():
            ensemble_proba += self.weights[model_name] * proba
            
        return ensemble_proba


class ABTestFramework:
    """A/Bæµ‹è¯•ç†è®ºæ¡†æ¶"""
    
    def __init__(self, significance_level: float = 0.05):
        self.significance_level = significance_level
        self.logger = logging.getLogger(f"{__name__}.ABTestFramework")
        
    def statistical_significance_test(self, model_a: BaseRiskModel, model_b: BaseRiskModel,
                                    X_test: np.ndarray, y_test: np.ndarray) -> ABTestResult:
        """ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ"""
        
        # æ¨¡å‹é¢„æµ‹
        pred_a = model_a.predict(X_test)
        pred_b = model_b.predict(X_test)
        
        accuracy_a = accuracy_score(y_test, pred_a)
        accuracy_b = accuracy_score(y_test, pred_b)
        
        # éº¦å…‹å†…é©¬æ£€éªŒ
        correct_a = (pred_a == y_test).astype(int)
        correct_b = (pred_b == y_test).astype(int)
        
        a_correct_b_wrong = np.sum((correct_a == 1) & (correct_b == 0))
        a_wrong_b_correct = np.sum((correct_a == 0) & (correct_b == 1))
        
        # éº¦å…‹å†…é©¬ç»Ÿè®¡é‡
        if a_correct_b_wrong + a_wrong_b_correct > 0:
            mcnemar_stat = (abs(a_correct_b_wrong - a_wrong_b_correct) - 1) ** 2 / (a_correct_b_wrong + a_wrong_b_correct)
            p_value = 1 - stats.chi2.cdf(mcnemar_stat, df=1)
        else:
            p_value = 1.0
            
        # æ•ˆåº”å¤§å°
        effect_size = abs(accuracy_a - accuracy_b)
        
        # åˆ¤æ–­æ˜¾è‘—æ€§å’Œè·èƒœè€…
        is_significant = p_value < self.significance_level
        if is_significant:
            winner = model_a.model_name if accuracy_a > accuracy_b else model_b.model_name
        else:
            winner = "æ— æ˜¾è‘—å·®å¼‚"
            
        return ABTestResult(
            model_a_name=model_a.model_name,
            model_b_name=model_b.model_name,
            p_value=p_value,
            effect_size=effect_size,
            is_significant=is_significant,
            winner=winner
        )


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¢å¼ºé£æ§æ¨¡å‹ç³»ç»Ÿ"""
    print("ğŸš€ å¢å¼ºé£æ§æ¨¡å‹ç³»ç»Ÿ - XGBoost + LightGBM + éšæœºæ£®æ—é›†æˆ")
    print("="*60)
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    print("ğŸ“Š ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    normal_data = AttackDataGenerator.generate_normal_data(800)
    crawler_data = AttackDataGenerator.generate_crawler_data(150)
    brute_force_data = AttackDataGenerator.generate_brute_force_data(100)
    order_fraud_data = AttackDataGenerator.generate_order_fraud_data(80)
    payment_fraud_data = AttackDataGenerator.generate_payment_fraud_data(70)
    ddos_data = AttackDataGenerator.generate_ddos_data(50)
    
    all_data = normal_data + crawler_data + brute_force_data + order_fraud_data + payment_fraud_data + ddos_data
    
    # è½¬æ¢ä¸ºæ•°ç»„æ ¼å¼
    feature_names = [
        'order_requests', 'payment_success', 'product_pv', 'risk_hits',
        'payment_success_rate', 'risk_hit_rate', 'pv_order_ratio',
        'hour_of_day', 'day_of_week', 'is_weekend', 'is_night',
        'time_offset', 'source_entropy', 'ip_entropy',
        'order_trend', 'payment_trend', 'pv_trend', 'risk_trend'
    ]
    
    X = []
    y = []
    
    for features in all_data:
        feature_array = np.array([
            features.order_requests, features.payment_success, features.product_pv, features.risk_hits,
            features.payment_success_rate, features.risk_hit_rate, features.pv_order_ratio,
            features.hour_of_day, features.day_of_week, int(features.is_weekend), int(features.is_night),
            features.time_offset, features.source_entropy, features.ip_entropy,
            features.order_trend, features.payment_trend, features.pv_trend, features.risk_trend
        ])
        X.append(feature_array)
        y.append(features.attack_type)
    
    X = np.array(X)
    y = np.array(y)
    
    # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
    
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape}, æµ‹è¯•é›†å¤§å°: {X_test.shape}")
    
    # 1. è®­ç»ƒä¸ªä½“æ¨¡å‹
    print("\nğŸ¯ è®­ç»ƒä¸ªä½“æ¨¡å‹...")
    
    # XGBoost
    xgb_model = XGBoostRiskModel()
    xgb_metrics = xgb_model.train_model(X_train, y_train)
    
    # LightGBM
    lgb_model = LightGBMRiskModel()
    lgb_metrics = lgb_model.train_model(X_train, y_train)
    
    # éšæœºæ£®æ—
    rf_model = RandomForestRiskModel()
    rf_metrics = rf_model.train_model(X_train, y_train)
    
    # 2. è®­ç»ƒé›†æˆæ¨¡å‹
    print("\nğŸ”¥ è®­ç»ƒé›†æˆæ¨¡å‹...")
    ensemble_model = EnsembleRiskModel()
    ensemble_metrics = ensemble_model.train_ensemble(X_train, y_train)
    
    # 3. A/Bæµ‹è¯•
    print("\nğŸ§ª æ‰§è¡ŒA/Bæµ‹è¯•...")
    ab_framework = ABTestFramework()
    
    # XGBoost vs LightGBM
    result1 = ab_framework.statistical_significance_test(xgb_model, lgb_model, X_test, y_test)
    print(f"XGBoost vs LightGBM: {result1.winner} (p-value: {result1.p_value:.4f})")
    
    # é›†æˆæ¨¡å‹è¯„ä¼°
    ensemble_pred = np.argmax(ensemble_model.predict_proba(X_test), axis=1)
    ensemble_accuracy = accuracy_score(y_test, ensemble_pred)
    
    print(f"\nğŸ“ˆ æœ€ç»ˆç»“æœ:")
    print(f"XGBoostå‡†ç¡®ç‡: {xgb_metrics.accuracy:.4f}")
    print(f"LightGBMå‡†ç¡®ç‡: {lgb_metrics.accuracy:.4f}")
    print(f"éšæœºæ£®æ—å‡†ç¡®ç‡: {rf_metrics.accuracy:.4f}")
    print(f"é›†æˆæ¨¡å‹å‡†ç¡®ç‡: {ensemble_accuracy:.4f}")
    
    print(f"\nğŸ† æ¨èä½¿ç”¨: é›†æˆæ¨¡å‹ (èåˆä¸‰ç§ç®—æ³•ä¼˜åŠ¿)")


if __name__ == "__main__":
    main()