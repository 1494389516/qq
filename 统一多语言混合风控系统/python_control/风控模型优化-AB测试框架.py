

"""
é£æ§æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ - éšæœºæ£®æ—å¢å¼º + LightGBMé›†æˆ + A/Bæµ‹è¯•æ¡†æ¶
åŸºäºé£æ§ç®—æ³•ä¸“å®¶çš„æ•°å­¦å»ºæ¨¡å’Œç†è®ºåˆ†æè§†è§’

æ ¸å¿ƒä¼˜åŒ–ç†è®ºï¼š
1. éšæœºæ£®æ—å‚æ•°ä¼˜åŒ–ä¸ç‰¹å¾å·¥ç¨‹
2. LightGBMæ¢¯åº¦æå‡é›†æˆ
3. è´å¶æ–¯A/Bæµ‹è¯•ç»Ÿè®¡æ¡†æ¶
4. å¤šç›®æ ‡ä¼˜åŒ–ä¸æ¨¡å‹è§£é‡Šæ€§
"""

import time
import numpy as np
import pandas as pd
import warnings
import logging
from typing import Dict, List, Tuple, Optional, Any, cast
from dataclasses import dataclass
from enum import Enum

# æ ¸å¿ƒæœºå™¨å­¦ä¹ åº“
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report
from sklearn.metrics import precision_score, recall_score, confusion_matrix
from scipy import stats
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    PLOTTING_AVAILABLE = True
except ImportError:
    PLOTTING_AVAILABLE = False

# LightGBM (å¦‚æœå¯ç”¨)
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    print("è­¦å‘Š: LightGBMæœªå®‰è£…ï¼Œå°†ä»…ä½¿ç”¨éšæœºæ£®æ—å’Œæç«¯éšæœºæ ‘")

warnings.filterwarnings('ignore')


class AttackType(Enum):
    """æ”»å‡»ç±»å‹æšä¸¾"""
    NORMAL = 0
    CRAWLER = 1
    BRUTE_FORCE = 2
    ORDER_FRAUD = 3
    PAYMENT_FRAUD = 4
    DDOS = 5


@dataclass 
class ModelPerformanceMetrics:
    """æ¨¡å‹æ€§èƒ½æŒ‡æ ‡"""
    accuracy: float
    precision: float
    recall: float
    f1_score: float
    auc_score: float
    training_time: float
    prediction_time: float
    feature_importance: Dict[str, float]
    

@dataclass
class ABTestResult:
    """A/Bæµ‹è¯•ç»“æœ"""
    model_a_name: str
    model_b_name: str
    sample_size: int
    p_value: float
    effect_size: float
    confidence_interval: Tuple[float, float]
    is_significant: bool
    winner: str
    business_impact: Dict[str, float]


class AdvancedFeatureEngineering:
    """é«˜çº§ç‰¹å¾å·¥ç¨‹ - åŸºäºé£æ§åœºæ™¯çš„ç‰¹å¾æ„é€ """
    
    def __init__(self):
        self.feature_names = [
            # åŸºç¡€KPIç‰¹å¾
            'order_requests', 'payment_success', 'product_pv', 'risk_hits',
            # æ¯”ç‡ç‰¹å¾ 
            'payment_success_rate', 'risk_hit_rate', 'pv_order_ratio',
            # æ—¶é—´ç‰¹å¾
            'hour_of_day', 'day_of_week', 'is_weekend', 'is_night',
            # ç†µå€¼ç‰¹å¾
            'time_offset', 'source_entropy', 'ip_entropy',
            # è¶‹åŠ¿ç‰¹å¾
            'order_trend', 'payment_trend', 'pv_trend', 'risk_trend',
            # é«˜çº§ç»„åˆç‰¹å¾
            'risk_payment_interaction', 'temporal_risk_score', 'behavior_consistency'
        ]
    
    @staticmethod
    def generate_enhanced_features(attack_type: AttackType, count: int) -> np.ndarray:
        """ç”Ÿæˆå¢å¼ºç‰¹å¾çŸ©é˜µ - åŸºäºæ”»å‡»ç‰¹å¾å·¥ç¨‹è§„èŒƒ"""
        np.random.seed(42 + attack_type.value)
        
        # åŸºç¡€ç‰¹å¾ç”Ÿæˆ
        if attack_type == AttackType.NORMAL:
            # æ­£å¸¸æµé‡ï¼šå¹³è¡¡çš„ä¸šåŠ¡æŒ‡æ ‡
            base_features = np.random.multivariate_normal(
                mean=[15, 12, 500, 2, 0.8, 0.13, 33, 12, 3, 0.5, 0.3, 50, 0.8, 0.9],
                cov=np.diag([9, 4, 2500, 1, 0.04, 0.01, 100, 36, 9, 0.25, 0.09, 2500, 0.04, 0.01]),
                size=count
            )
        elif attack_type == AttackType.CRAWLER:
            # çˆ¬è™«æ”»å‡»ï¼šé«˜PVï¼Œä½è½¬åŒ–ï¼Œå¼‚å¸¸ç†µå€¼
            base_features = np.random.multivariate_normal(
                mean=[8, 2, 2000, 8, 0.25, 1.0, 250, 12, 3, 0.5, 0.3, 100, 0.3, 0.4],
                cov=np.diag([4, 1, 90000, 4, 0.01, 0.04, 2500, 36, 9, 0.25, 0.09, 10000, 0.04, 0.04]),
                size=count
            )
        elif attack_type == AttackType.BRUTE_FORCE:
            # æš´åŠ›ç ´è§£ï¼šé«˜é¢‘è¯·æ±‚ï¼Œæä½æˆåŠŸç‡
            base_features = np.random.multivariate_normal(
                mean=[80, 2, 300, 25, 0.025, 0.31, 3.75, 12, 3, 0.5, 0.7, 200, 0.2, 0.2],
                cov=np.diag([225, 1, 2500, 25, 0.0001, 0.01, 1, 36, 9, 0.25, 0.09, 10000, 0.04, 0.04]),
                size=count
            )
        elif attack_type == AttackType.ORDER_FRAUD:
            # è®¢å•æ¬ºè¯ˆï¼šè®¢å•æ”¯ä»˜æ¨¡å¼å¼‚å¸¸
            base_features = np.random.multivariate_normal(
                mean=[40, 35, 600, 12, 0.875, 0.3, 15, 12, 3, 0.5, 0.3, 150, 0.55, 0.65],
                cov=np.diag([64, 25, 10000, 9, 0.01, 0.01, 25, 36, 9, 0.25, 0.09, 6400, 0.04, 0.04]),
                size=count
            )
        elif attack_type == AttackType.PAYMENT_FRAUD:
            # æ”¯ä»˜æ¬ºè¯ˆï¼šæ”¯ä»˜ç¯èŠ‚é«˜é£é™©
            base_features = np.random.multivariate_normal(
                mean=[25, 3, 400, 18, 0.12, 0.72, 16, 12, 3, 0.5, 0.3, 300, 0.45, 0.55],
                cov=np.diag([25, 4, 3600, 16, 0.01, 0.04, 16, 36, 9, 0.25, 0.09, 22500, 0.04, 0.04]),
                size=count
            )
        else:  # DDOS
            # DDoSæ”»å‡»ï¼šæé«˜æµé‡å†²å‡»
            base_features = np.random.multivariate_normal(
                mean=[200, 1, 8000, 50, 0.005, 0.25, 40, 12, 3, 0.5, 0.3, 500, 0.15, 0.25],
                cov=np.diag([1600, 1, 1000000, 100, 0.00001, 0.01, 100, 36, 9, 0.25, 0.09, 40000, 0.04, 0.04]),
                size=count
            )
        
        # ç¡®ä¿éè´Ÿå€¼
        base_features = np.abs(base_features)
        
        # æ·»åŠ è¶‹åŠ¿ç‰¹å¾
        trends = np.random.normal(0, [0.5, 0.3, 2, 0.2], (count, 4))
        
        # æ„é€ é«˜çº§ç»„åˆç‰¹å¾
        advanced_features = np.zeros((count, 3))
        
        # é£é™©-æ”¯ä»˜äº¤äº’ç‰¹å¾
        advanced_features[:, 0] = base_features[:, 3] * (1 - base_features[:, 4])  # risk_hits * (1 - payment_rate)
        
        # æ—¶é—´é£é™©åˆ†æ•° 
        night_factor = base_features[:, 10] * 1.5 + 1  # å¤œé—´åŠ æƒ
        advanced_features[:, 1] = base_features[:, 3] * night_factor
        
        # è¡Œä¸ºä¸€è‡´æ€§åˆ†æ•°
        expected_pv = base_features[:, 0] * 30  # é¢„æœŸPV
        pv_deviation = np.abs(base_features[:, 2] - expected_pv) / (expected_pv + 1)
        advanced_features[:, 2] = 1 / (1 + pv_deviation)  # ä¸€è‡´æ€§åˆ†æ•°
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        features = np.hstack([base_features, trends, advanced_features])
        
        return features
    
    @staticmethod
    def generate_balanced_dataset(total_samples: int = 3000) -> Tuple[np.ndarray, np.ndarray]:
        """ç”Ÿæˆå¹³è¡¡çš„é£æ§æ•°æ®é›†"""
        # å„æ”»å‡»ç±»å‹æ ·æœ¬åˆ†é… (ç¬¦åˆçœŸå®ä¸šåŠ¡åˆ†å¸ƒ)
        samples_per_class = {
            AttackType.NORMAL: int(total_samples * 0.65),      # æ­£å¸¸æµé‡å ä¸»å¯¼
            AttackType.CRAWLER: int(total_samples * 0.15),     # çˆ¬è™«æ”»å‡»è¾ƒå¸¸è§
            AttackType.BRUTE_FORCE: int(total_samples * 0.08), # æš´åŠ›ç ´è§£
            AttackType.ORDER_FRAUD: int(total_samples * 0.06), # è®¢å•æ¬ºè¯ˆ
            AttackType.PAYMENT_FRAUD: int(total_samples * 0.04), # æ”¯ä»˜æ¬ºè¯ˆ
            AttackType.DDOS: int(total_samples * 0.02)         # DDoSæ”»å‡»è¾ƒå°‘
        }
        
        X_list: List[np.ndarray] = []
        y_list: List[np.ndarray] = []
        
        for attack_type, count in samples_per_class.items():
            if count > 0:
                features = AdvancedFeatureEngineering.generate_enhanced_features(attack_type, count)
                labels = np.full(count, attack_type.value)
                
                X_list.append(features)
                y_list.append(labels)
        
        X = np.vstack(X_list)
        y = np.hstack(y_list)
        
        # éšæœºæ‰“ä¹±æ•°æ®
        indices = np.random.permutation(len(X))
        X = X[indices]
        y = y[indices]
        
        return X, y


class OptimizedRandomForestModel:
    """ä¼˜åŒ–çš„éšæœºæ£®æ—æ¨¡å‹"""
    
    def __init__(self, optimization_level: str = 'advanced'):
        self.optimization_level = optimization_level
        self.model = None
        self.feature_names = AdvancedFeatureEngineering().feature_names
        self.training_metrics = None
        
        # æ—¥å¿—é…ç½®
        self.logger = logging.getLogger(f"{__name__}.RandomForest")
    
    def train_with_hyperparameter_tuning(self, X_train: np.ndarray, y_train: np.ndarray, 
                                        X_val: np.ndarray, y_val: np.ndarray) -> ModelPerformanceMetrics:
        """å¸¦è¶…å‚æ•°è°ƒä¼˜çš„è®­ç»ƒ"""
        self.logger.info(f"å¼€å§‹è®­ç»ƒä¼˜åŒ–éšæœºæ£®æ—æ¨¡å‹ (ä¼˜åŒ–çº§åˆ«: {self.optimization_level})...")
        start_time = time.time()
        
        if self.optimization_level == 'basic':
            # åŸºç¡€é…ç½®
            param_grid = {
                'n_estimators': [100, 200],
                'max_depth': [10, 15],
                'min_samples_split': [5, 10],
                'min_samples_leaf': [2, 4]
            }
        elif self.optimization_level == 'advanced':
            # é«˜çº§é…ç½®
            param_grid = {
                'n_estimators': [200, 300, 400],
                'max_depth': [12, 15, 18],
                'min_samples_split': [5, 8, 12],
                'min_samples_leaf': [2, 3, 5],
                'max_features': ['sqrt', 'log2', 0.8]
                
            }
        else:  # expert
            # ä¸“å®¶çº§é…ç½®
            param_grid = {
                'n_estimators': [300, 400, 500],
                'max_depth': [15, 18, 22],
                'min_samples_split': [5, 8, 12, 15],
                'min_samples_leaf': [2, 3, 5, 8],
                'max_features': ['sqrt', 'log2', 0.6, 0.8, 1.0],
                'min_impurity_decrease': [0.0, 0.001, 0.01]
            }
        
        # ç½‘æ ¼æœç´¢ä¼˜åŒ–
        base_model = RandomForestClassifier(
            bootstrap=True,
            random_state=42,
            n_jobs=-1,
            class_weight='balanced',
            criterion='gini'
        )
        
        grid_search = GridSearchCV(
            base_model, 
            param_grid, 
            cv=3,
            scoring='f1_weighted',
            n_jobs=-1,
            verbose=1
        )
        
        grid_search.fit(X_train, y_train)
        self.model = grid_search.best_estimator_
        
        training_time = time.time() - start_time
        
        # è¯„ä¼°æ€§èƒ½
        start_pred_time = time.time()
        y_pred = self.model.predict(X_val)
        y_proba = self.model.predict_proba(X_val)
        prediction_time = time.time() - start_pred_time
        
        # ç‰¹å¾é‡è¦æ€§
        feature_importance = dict(zip(self.feature_names, self.model.feature_importances_))
        
        metrics = ModelPerformanceMetrics(
            accuracy=float(accuracy_score(y_val, y_pred)),
            precision=float(precision_score(y_val, y_pred, average='weighted', zero_division='warn')),
            recall=float(recall_score(y_val, y_pred, average='weighted', zero_division='warn')),
            f1_score=float(f1_score(y_val, y_pred, average='weighted', zero_division='warn')),
            auc_score=float(roc_auc_score(y_val, y_proba, multi_class='ovr', average='weighted')),
            training_time=training_time,
            prediction_time=prediction_time,
            feature_importance=feature_importance
        )
        
        self.training_metrics = metrics
        
        self.logger.info(f"éšæœºæ£®æ—è®­ç»ƒå®Œæˆ - F1: {metrics.f1_score:.4f}, æœ€ä½³å‚æ•°: {grid_search.best_params_}")
        return metrics


class LightGBMModel:
    """LightGBMæ¨¡å‹"""
    
    def __init__(self):
        self.model = None
        self.feature_names = AdvancedFeatureEngineering().feature_names
        self.training_metrics = None
        self.logger = logging.getLogger(f"{__name__}.LightGBM")
    
    def train_optimized(self, X_train: np.ndarray, y_train: np.ndarray,
                       X_val: np.ndarray, y_val: np.ndarray) -> Optional[ModelPerformanceMetrics]:
        """è®­ç»ƒä¼˜åŒ–çš„LightGBMæ¨¡å‹"""
        if not LIGHTGBM_AVAILABLE:
            self.logger.warning("LightGBMä¸å¯ç”¨ï¼Œè·³è¿‡è®­ç»ƒ")
            return None
            
        self.logger.info("å¼€å§‹è®­ç»ƒLightGBMæ¨¡å‹...")
        start_time = time.time()
        
        # LightGBMä¼˜åŒ–é…ç½® - ç¡®ä¿lgbå·²å¯¼å…¥
        # å¯¼å…¥lgbæ¨¡å—çš„å¼•ç”¨ç¡®ä¿å¯ç”¨
        import lightgbm as lgb_module
        
        model = lgb_module.LGBMClassifier(
            objective='multiclass',
            num_class=6,
            metric='multi_logloss',
            boosting_type='gbdt',
            n_estimators=200,
            learning_rate=0.1,
            max_depth=12,
            num_leaves=31,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=1.0,
            min_child_samples=20,
            min_child_weight=0.001,
            random_state=42,
            n_jobs=-1,
            verbosity=-1
        )
        
        # è®­ç»ƒæ¨¡å‹
        model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            callbacks=[lgb_module.early_stopping(20), lgb_module.log_evaluation(0)]
        )
        
        self.model = model
        training_time = time.time() - start_time
        
        # è¯„ä¼°æ€§èƒ½
        start_pred_time = time.time()
        y_pred = model.predict(X_val)
        y_proba = model.predict_proba(X_val)
        prediction_time = time.time() - start_pred_time
        
        # ç‰¹å¾é‡è¦æ€§
        feature_importance = dict(zip(self.feature_names, model.feature_importances_))
        
        metrics = ModelPerformanceMetrics(
            accuracy=float(accuracy_score(y_val, y_pred)),
            precision=float(precision_score(y_val, y_pred, average='weighted', zero_division='warn')),
            recall=float(recall_score(y_val, y_pred, average='weighted', zero_division='warn')),
            f1_score=float(f1_score(y_val, y_pred, average='weighted', zero_division='warn')),
            auc_score=float(roc_auc_score(y_val, y_proba, multi_class='ovr', average='weighted')),
            training_time=training_time,
            prediction_time=prediction_time,
            feature_importance=feature_importance
        )
        
        self.training_metrics = metrics
        
        self.logger.info(f"LightGBMè®­ç»ƒå®Œæˆ - F1: {metrics.f1_score:.4f}")
        return metrics


class BayesianABTestFramework:
    """è´å¶æ–¯A/Bæµ‹è¯•æ¡†æ¶"""
    
    def __init__(self, significance_level: float = 0.05):
        self.significance_level = significance_level
        self.logger = logging.getLogger(f"{__name__}.BayesianABTest")
    
    def mcnemar_test_with_business_metrics(self, model_a_name: str, model_b_name: str,
                                         pred_a: np.ndarray, pred_b: np.ndarray,
                                         y_true: np.ndarray) -> ABTestResult:
        """éº¦å…‹å†…é©¬æ£€éªŒåŠ ä¸šåŠ¡æŒ‡æ ‡åˆ†æ"""
        
        # åŸºç¡€ç»Ÿè®¡æ£€éªŒ
        correct_a = (pred_a == y_true).astype(int)
        correct_b = (pred_b == y_true).astype(int)
        
        # æ··æ·†çŸ©é˜µ
        both_correct = np.sum((correct_a == 1) & (correct_b == 1))
        a_correct_b_wrong = np.sum((correct_a == 1) & (correct_b == 0))
        a_wrong_b_correct = np.sum((correct_a == 0) & (correct_b == 1))
        both_wrong = np.sum((correct_a == 0) & (correct_b == 0))
        
        # éº¦å…‹å†…é©¬ç»Ÿè®¡é‡
        discordant_pairs = a_correct_b_wrong + a_wrong_b_correct
        
        if discordant_pairs == 0:
            p_value = 1.0
            effect_size = 0.0
        else:
            mcnemar_statistic = (abs(a_correct_b_wrong - a_wrong_b_correct) - 1) ** 2 / discordant_pairs
            p_value = 1 - stats.chi2.cdf(mcnemar_statistic, df=1)
            effect_size = a_correct_b_wrong / a_wrong_b_correct if a_wrong_b_correct > 0 else float('inf')
        
        # å‡†ç¡®ç‡å·®å¼‚å’Œç½®ä¿¡åŒºé—´
        accuracy_a = np.mean(correct_a)
        accuracy_b = np.mean(correct_b)
        accuracy_diff = accuracy_a - accuracy_b
        
        n = len(y_true)
        se_diff = np.sqrt((accuracy_a * (1 - accuracy_a) + accuracy_b * (1 - accuracy_b)) / n)
        margin_error = stats.norm.ppf(1 - self.significance_level / 2) * se_diff
        ci_lower = accuracy_diff - margin_error
        ci_upper = accuracy_diff + margin_error
        
        # ä¸šåŠ¡å½±å“åˆ†æ
        business_impact = self._calculate_business_impact(pred_a, pred_b, y_true)
        
        # åˆ¤æ–­è·èƒœè€…
        is_significant_bool = bool(p_value < self.significance_level)
        if is_significant_bool:
            winner = model_a_name if accuracy_a > accuracy_b else model_b_name
        else:
            winner = "æ— æ˜¾è‘—å·®å¼‚"
        
        return ABTestResult(
            model_a_name=model_a_name,
            model_b_name=model_b_name,
            sample_size=len(y_true),
            p_value=float(p_value),
            effect_size=float(effect_size) if not np.isinf(effect_size) else 999.0,
            confidence_interval=(float(ci_lower), float(ci_upper)),
            is_significant=is_significant_bool,
            winner=winner,
            business_impact=business_impact
        )
    
    def _calculate_business_impact(self, pred_a: np.ndarray, pred_b: np.ndarray, 
                                  y_true: np.ndarray) -> Dict[str, float]:
        """è®¡ç®—ä¸šåŠ¡å½±å“æŒ‡æ ‡"""
        
        # å‡é˜³æ€§ç‡ (æ­£å¸¸æµé‡è¢«è¯¯åˆ¤ä¸ºæ”»å‡»)
        normal_mask = (y_true == 0)
        if np.sum(normal_mask) > 0:
            fp_rate_a = np.sum(pred_a[normal_mask] != 0) / np.sum(normal_mask)
            fp_rate_b = np.sum(pred_b[normal_mask] != 0) / np.sum(normal_mask)
            fp_improvement = (fp_rate_a - fp_rate_b) / fp_rate_a * 100 if fp_rate_a > 0 else 0
        else:
            fp_improvement = 0
        
        # å‡é˜´æ€§ç‡ (æ”»å‡»æµé‡è¢«è¯¯åˆ¤ä¸ºæ­£å¸¸)
        attack_mask = (y_true != 0)
        if np.sum(attack_mask) > 0:
            fn_rate_a = np.sum(pred_a[attack_mask] == 0) / np.sum(attack_mask)
            fn_rate_b = np.sum(pred_b[attack_mask] == 0) / np.sum(attack_mask)
            fn_improvement = (fn_rate_a - fn_rate_b) / fn_rate_a * 100 if fn_rate_a > 0 else 0
        else:
            fn_improvement = 0
        
        # å…³é”®æ”»å‡»æ£€æµ‹ç‡ (DDoS, æš´åŠ›ç ´è§£)
        critical_mask = np.isin(y_true, [AttackType.DDOS.value, AttackType.BRUTE_FORCE.value])
        if np.sum(critical_mask) > 0:
            critical_recall_a = np.sum(pred_a[critical_mask] == y_true[critical_mask]) / np.sum(critical_mask)
            critical_recall_b = np.sum(pred_b[critical_mask] == y_true[critical_mask]) / np.sum(critical_mask)
            critical_improvement = (critical_recall_b - critical_recall_a) / critical_recall_a * 100 if critical_recall_a > 0 else 0
        else:
            critical_improvement = 0
        
        return {
            'false_positive_reduction_pct': fp_improvement,
            'false_negative_reduction_pct': fn_improvement,
            'critical_attack_detection_improvement_pct': critical_improvement,
            'overall_accuracy_improvement_pct': (accuracy_score(y_true, pred_b) - accuracy_score(y_true, pred_a)) / accuracy_score(y_true, pred_a) * 100
        }


def main():
    """ä¸»å‡½æ•° - é£æ§æ¨¡å‹ä¼˜åŒ–ä¸A/Bæµ‹è¯•æ¼”ç¤º"""
    print("ğŸš€ é£æ§æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ - éšæœºæ£®æ—å¢å¼º + LightGBM + A/Bæµ‹è¯•")
    print("="*70)
    
    # 1. ç”Ÿæˆå¢å¼ºç‰¹å¾æ•°æ®é›†
    print("ğŸ“Š ç”Ÿæˆå¢å¼ºç‰¹å¾å·¥ç¨‹æ•°æ®é›†...")
    X: np.ndarray
    y: np.ndarray
    X, y = AdvancedFeatureEngineering.generate_balanced_dataset(total_samples=4000)
    # å¼ºåˆ¶ç±»å‹è½¬æ¢ä»¥è§£å†³ç±»å‹æ¨æ–­é—®é¢˜
    X = cast(np.ndarray, X)
    y = cast(np.ndarray, y)
    
    print(f"æ•°æ®é›†è§„æ¨¡: {X.shape}")
    print(f"ç‰¹å¾ç»´åº¦: {len(AdvancedFeatureEngineering().feature_names)}")
    print(f"ç±»åˆ«åˆ†å¸ƒ: {dict(zip(['æ­£å¸¸', 'çˆ¬è™«', 'æš´åŠ›ç ´è§£', 'è®¢å•æ¬ºè¯ˆ', 'æ”¯ä»˜æ¬ºè¯ˆ', 'DDoS'], np.bincount(y)))}")
    
    # 2. æ•°æ®é¢„å¤„ç†å’Œåˆ†å‰²
    scaler = StandardScaler()
    X_scaled: np.ndarray = scaler.fit_transform(X)
    
    # ä¸‰é‡åˆ†å‰²ï¼šè®­ç»ƒ/éªŒè¯/æµ‹è¯•
    temp_result = train_test_split(
        X_scaled, y, test_size=0.25, random_state=42, stratify=y
    )
    X_temp: np.ndarray = cast(np.ndarray, temp_result[0])
    X_test: np.ndarray = cast(np.ndarray, temp_result[1])
    y_temp: np.ndarray = cast(np.ndarray, temp_result[2])
    y_test: np.ndarray = cast(np.ndarray, temp_result[3])
    
    train_result = train_test_split(
        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
    )
    X_train: np.ndarray = cast(np.ndarray, train_result[0])
    X_val: np.ndarray = cast(np.ndarray, train_result[1])
    y_train: np.ndarray = cast(np.ndarray, train_result[2])
    y_val: np.ndarray = cast(np.ndarray, train_result[3])
    
    print(f"\næ•°æ®åˆ†å‰² - è®­ç»ƒé›†: {X_train.shape}, éªŒè¯é›†: {X_val.shape}, æµ‹è¯•é›†: {X_test.shape}")
    
    # 3. è®­ç»ƒä¼˜åŒ–æ¨¡å‹
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒä¼˜åŒ–æ¨¡å‹...")
    
    # éšæœºæ£®æ— - åŸºç¡€ç‰ˆ
    rf_basic = OptimizedRandomForestModel(optimization_level='basic')
    rf_basic_metrics = rf_basic.train_with_hyperparameter_tuning(X_train, y_train, X_val, y_val)
    
    # éšæœºæ£®æ— - é«˜çº§ç‰ˆ  
    rf_advanced = OptimizedRandomForestModel(optimization_level='advanced')
    rf_advanced_metrics = rf_advanced.train_with_hyperparameter_tuning(X_train, y_train, X_val, y_val)
    
    # LightGBMæ¨¡å‹
    lgb_model = LightGBMModel()
    lgb_metrics = lgb_model.train_optimized(X_train, y_train, X_val, y_val)
    
    # 4. æ€§èƒ½å¯¹æ¯”åˆ†æ
    print("\nğŸ“ˆ æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ:")
    print("-" * 80)
    
    models_info = [
        ('éšæœºæ£®æ—-åŸºç¡€ç‰ˆ', rf_basic_metrics),
        ('éšæœºæ£®æ—-é«˜çº§ç‰ˆ', rf_advanced_metrics)
    ]
    
    if lgb_metrics is not None:
        models_info.append(('LightGBM', lgb_metrics))
    
    for model_name, metrics in models_info:
        print(f"{model_name:15} | F1: {metrics.f1_score:.4f} | å‡†ç¡®ç‡: {metrics.accuracy:.4f} | "
              f"AUC: {metrics.auc_score:.4f} | è®­ç»ƒæ—¶é—´: {metrics.training_time:.2f}s")
    
    # 5. ç‰¹å¾é‡è¦æ€§åˆ†æ
    print("\nğŸ” ç‰¹å¾é‡è¦æ€§åˆ†æ (Top 10):")
    print("-" * 50)
    
    # æ˜¾ç¤ºé«˜çº§éšæœºæ£®æ—çš„ç‰¹å¾é‡è¦æ€§
    top_features = sorted(rf_advanced_metrics.feature_importance.items(), 
                         key=lambda x: x[1], reverse=True)[:10]
    
    for i, (feature, importance) in enumerate(top_features, 1):
        print(f"{i:2d}. {feature:25} {importance:.4f}")
    
    # 6. A/Bæµ‹è¯•ç»Ÿè®¡åˆ†æ
    print("\nğŸ§ª A/Bæµ‹è¯•ç»Ÿè®¡åˆ†æ:")
    print("=" * 50)
    
    ab_framework = BayesianABTestFramework()
    
    # åœ¨æµ‹è¯•é›†ä¸Šè·å–é¢„æµ‹ç»“æœ
    test_predictions = {}
    available_models = []
    
    if rf_basic.model is not None:
        test_predictions['RF-åŸºç¡€ç‰ˆ'] = rf_basic.model.predict(X_test)
        available_models.append(('RF-åŸºç¡€ç‰ˆ', rf_basic.model))
    
    if rf_advanced.model is not None:
        test_predictions['RF-é«˜çº§ç‰ˆ'] = rf_advanced.model.predict(X_test)
        available_models.append(('RF-é«˜çº§ç‰ˆ', rf_advanced.model))
    
    if lgb_model.model is not None:
        test_predictions['LightGBM'] = lgb_model.model.predict(X_test)
        available_models.append(('LightGBM', lgb_model.model))
    
    # æ‰§è¡Œä¸¤ä¸¤A/Bæµ‹è¯•
    ab_results = []
    model_names = list(test_predictions.keys())
    
    for i in range(len(model_names)):
        for j in range(i + 1, len(model_names)):
            model_a, model_b = model_names[i], model_names[j]
            
            result = ab_framework.mcnemar_test_with_business_metrics(
                model_a, model_b,
                test_predictions[model_a],
                test_predictions[model_b],
                y_test
            )
            ab_results.append(result)
            
            # è¾“å‡ºA/Bæµ‹è¯•ç»“æœ
            print(f"\n{model_a} vs {model_b}:")
            print(f"  æ ·æœ¬å¤§å°: {result.sample_size}")
            print(f"  p-value: {result.p_value:.6f}")
            print(f"  æ•ˆåº”å¤§å°: {result.effect_size:.4f}")
            print(f"  ç»Ÿè®¡æ˜¾è‘—æ€§: {'æ˜¯' if result.is_significant else 'å¦'}")
            print(f"  è·èƒœè€…: {result.winner}")
            print(f"  ç½®ä¿¡åŒºé—´: [{result.confidence_interval[0]:.4f}, {result.confidence_interval[1]:.4f}]")
            
            # ä¸šåŠ¡å½±å“åˆ†æ
            print(f"  ä¸šåŠ¡å½±å“:")
            for metric, value in result.business_impact.items():
                print(f"    {metric}: {value:.2f}%")
    
    # 7. æœ€ç»ˆç»“è®ºå’Œå»ºè®®
    print("\nğŸ† æœ€ç»ˆç»“è®ºå’Œç®—æ³•ç†è®ºåˆ†æ:")
    print("=" * 70)
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_model_info = max(models_info, key=lambda x: x[1].f1_score)
    best_model_name, best_metrics = best_model_info
    
    print(f"\næ¨èæœ€ä½³æ¨¡å‹: {best_model_name}")
    print(f"æ€§èƒ½æŒ‡æ ‡: F1={best_metrics.f1_score:.4f}, AUC={best_metrics.auc_score:.4f}")
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§æ€»ç»“
    significant_results = [r for r in ab_results if r.is_significant]
    print(f"\nç»Ÿè®¡æ˜¾è‘—æ€§ç»“æœ: {len(significant_results)}/{len(ab_results)} ç»„å¯¹æ¯”å…·æœ‰æ˜¾è‘—å·®å¼‚")
    
    # ç®—æ³•ç†è®ºæ€»ç»“
    print("\nğŸ“š ç®—æ³•ç†è®ºä¸ä¼˜åŒ–ç­–ç•¥æ€»ç»“:")
    print("\n1. éšæœºæ£®æ—ä¼˜åŒ–ç†è®º:")
    print("   â€¢ åŸºç¡€ç‰ˆ vs é«˜çº§ç‰ˆ: é€šè¿‡è¶…å‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–")
    print("   â€¢ ç‰¹å¾å·¥ç¨‹: å¼•å…¥é«˜çº§ç»„åˆç‰¹å¾å’Œäº¤äº’é¡¹")
    print("   â€¢ ç±»åˆ«å‡è¡¡: ä½¿ç”¨balancedæƒé‡å¤„ç†ä¸å¹³è¡¡æ•°æ®")
    
    if LIGHTGBM_AVAILABLE:
        print("\n2. LightGBM vs éšæœºæ£®æ—å¯¹æ¯”:")
        print("   â€¢ LightGBM: æ¢¯åº¦æå‡ï¼ŒåŸºäºç›´æ–¹å›¾ä¼˜åŒ–ï¼Œå¶å­ç”Ÿé•¿ç­–ç•¥")
        print("   â€¢ éšæœºæ£®æ—: å¹¶è¡Œbaggingï¼Œå‡å°‘æ–¹å·®ï¼Œå¯è§£é‡Šæ€§å¼º")
        print("   â€¢ é€‰æ‹©å»ºè®®: æ ¹æ®æ•°æ®è§„æ¨¡å’Œè§£é‡Šæ€§éœ€æ±‚å†³å®š")
    
    print("\n3. A/Bæµ‹è¯•ç†è®ºæ¡†æ¶:")
    print("   â€¢ éº¦å…‹å†…é©¬æ£€éªŒ: é€‚ç”¨äºé…å¯¹æ ·æœ¬çš„äºŒåˆ†ç±»ç»“æœæ¯”è¾ƒ")
    print("   â€¢ ä¸šåŠ¡æŒ‡æ ‡: å…³æ³¨å‡é˜³æ€§/å‡é˜´æ€§å¯¹ä¸šåŠ¡çš„å®é™…å½±å“")
    print("   â€¢ ç½®ä¿¡åŒºé—´: æä¾›å‡†ç¡®ç‡å·®å¼‚çš„ä¸ç¡®å®šæ€§é‡åŒ–")
    
    print("\n4. ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–:")
    print("   â€¢ åŸºç¡€KPI + æ¯”ç‡ç‰¹å¾ + æ—¶é—´ç‰¹å¾ + ç†µå€¼ç‰¹å¾")
    print("   â€¢ é«˜çº§ç»„åˆ: é£é™©-æ”¯ä»˜äº¤äº’ã€æ—¶é—´é£é™©åˆ†æ•°ã€è¡Œä¸ºä¸€è‡´æ€§")
    print("   â€¢ é¢†åŸŸçŸ¥è¯†: åŸºäºé£æ§ä¸šåŠ¡åœºæ™¯çš„ç‰¹å¾æ„é€ ")
    
    print("\nâœ… é£æ§æ¨¡å‹ä¼˜åŒ–å®Œæˆ! å»ºè®®æ ¹æ®A/Bæµ‹è¯•ç»“æœé€‰æ‹©æœ€ä¼˜æ¨¡å‹éƒ¨ç½²ã€‚")


if __name__ == "__main__":
    main()