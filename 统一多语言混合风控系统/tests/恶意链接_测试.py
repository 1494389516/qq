import os

# æµ‹è¯•æ¶æ„é“¾æ¥æ£€æµ‹ä»£ç 
import sys
import warnings
warnings.filterwarnings('ignore')  # å¿½ç•¥è­¦å‘Šä¿¡æ¯

try:
    import pandas as pd
    import numpy as np
    import tldextract
    import re
    from sklearn.ensemble import IsolationForest
    from sklearn.preprocessing import StandardScaler
    from collections import Counter
    import time
    print("âœ… æ‰€æœ‰ä¾èµ–åº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥åº“å¤±è´¥: {e}")
    sys.exit(1)

# æ¨¡æ‹Ÿæµ‹è¯•æ•°æ®
print("\nğŸ”„ åˆ›å»ºæµ‹è¯•æ•°æ®...")
data = {
    'user_id': [1, 1, 1, 1, 2],
    'timestamp': ['2025-09-25 12:00:00', '2025-09-25 12:05:00', '2025-09-25 12:10:00', '2025-09-25 12:15:00', '2025-09-25 12:00:00'],
    'url': ['http://example.com/offer?id=1', 
            'http://malicious.com/bad-link', 
            'http://example.com/offer?id=2', 
            'http://malicious.com/phishing', 
            'http://example.com/offer?id=3']
}

df = pd.DataFrame(data)
df['timestamp'] = pd.to_datetime(df['timestamp'])
print(f"âœ… æµ‹è¯•æ•°æ®åˆ›å»ºæˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")

# ç®€åŒ–çš„URLç‰¹å¾æå–
def extract_url_features_simple(url):
    try:
        # åŸºç¡€ç‰¹å¾
        url_length = len(url)
        has_https = 1 if url.startswith('https') else 0
        
        # ç®€å•å…³é”®è¯æ£€æµ‹
        suspicious_keywords = ['bad', 'phishing', 'malicious']
        keyword_score = sum([1 for word in suspicious_keywords if word in url.lower()])
        
        return {
            'url_length': url_length,
            'has_https': has_https,
            'keyword_score': keyword_score,
        }
    except Exception as e:
        print(f"âš ï¸ URLè§£æé”™è¯¯: {url}, é”™è¯¯: {e}")
        return {'url_length': 0, 'has_https': 0, 'keyword_score': 0}

print("\nğŸ”„ æå–URLç‰¹å¾...")
features = df['url'].apply(extract_url_features_simple)
features_df = pd.DataFrame(features.tolist())
df = pd.concat([df, features_df], axis=1)
print("âœ… URLç‰¹å¾æå–å®Œæˆ")

# ç®€åŒ–çš„é£é™©è¯„åˆ†
def calculate_simple_risk_score(row):
    score = 0
    score += row['url_length'] * 0.01
    score += row['keyword_score'] * 3.0
    score -= row['has_https'] * 1.0
    return max(0, score)

print("\nğŸ”„ è®¡ç®—é£é™©è¯„åˆ†...")
df['risk_score'] = df.apply(calculate_simple_risk_score, axis=1)
print("âœ… é£é™©è¯„åˆ†è®¡ç®—å®Œæˆ")

# å¼‚å¸¸æ£€æµ‹
print("\nğŸ”„ æ‰§è¡Œå¼‚å¸¸æ£€æµ‹...")
try:
    feature_columns = ['url_length', 'keyword_score', 'has_https']
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(df[feature_columns])
    
    model = IsolationForest(contamination='auto', random_state=42)
    anomaly_labels = model.fit_predict(scaled_features)
    anomaly_scores = model.decision_function(scaled_features)
    
    df['anomaly'] = anomaly_labels
    df['anomaly_score'] = anomaly_scores
    print("âœ… å¼‚å¸¸æ£€æµ‹å®Œæˆ")
except Exception as e:
    print(f"âŒ å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
    sys.exit(1)

# æ˜¾ç¤ºç»“æœ
print("\nğŸ“Š æ£€æµ‹ç»“æœ:")
print("=" * 60)
for idx, row in df.iterrows():
    status = "ğŸš¨ æ¶æ„" if row['anomaly'] == -1 else "âœ… æ­£å¸¸"
    print(f"{status} | ç”¨æˆ·{row['user_id']} | é£é™©è¯„åˆ†: {row['risk_score']:.2f}")
    print(f"      URL: {row['url']}")
    print(f"      å¼‚å¸¸è¯„åˆ†: {row['anomaly_score']:.3f}")
    print("-" * 60)

print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼ä»£ç è¿è¡Œæ­£å¸¸ã€‚")